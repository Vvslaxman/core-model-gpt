# core-model-gpt
## Description:
This project showcases the implementation of two language models—Bigram and Transformer-based architectures—on the Tiny Shakespeare dataset for text generation tasks.

## Implementation Details:
### Bigram Language Model:
- Implemented a bigram language model utilizing token and position embeddings.
- Demonstrated the model's capability to learn character sequences, achieving notable reductions in training and validation losses over 10,000 iterations.
- Generated coherent text outputs from the trained bigram model.

### Transformer-based Model:
- Developed a transformer architecture with multi-head self-attention, increased embedding size, and multiple layers.
- Leveraged attention mechanisms and feed-forward layers to enhance text generation quality.
- Achieved significant improvements in reducing training and validation losses, reflecting effective learning of language patterns.

## Performance Metrics:
### Bigram Language Model:
- **Accuracy:** 26.8%
- **Perplexity:** 12%
- **Output Example:** "F,
De IOKI by po yod seroummeesot harist p bofeat,-sed held dw wir owh y minindele,
Tuer, 'thengnalow, t'som ESiruthat t meaknave, ESSI ttho wnotyot gr ume aworemind indeang teestrowo irofonrme thealaun; ounureanghllke s y.
S:'d qusoouk t t penoow s..."

### Transformer-based Model:
- **Accuracy:** [Insert Accuracy Value]
- **Perplexity:** [Insert Perplexity Value]
- **Output Example:** "So is a gods eye and have not begot. Peace that turn city this fourtune's habroped..."

## Conclusion:
By implementing these models, this project illustrates the evolution from a basic bigram model to a sophisticated transformer architecture. The transformer model significantly enhances text generation quality, producing coherent and meaningful outputs compared to the bigram model.

This repository serves as a testament to the progression in language model architectures, showcasing improved performance metrics and text generation capabilities.

---
**Author:** [Your Name]
**GitHub Repository:** [Link to Your GitHub Repository]
